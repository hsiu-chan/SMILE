{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# import matplotlib.pyplot as plt\n",
    "# import cv2\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "import math\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import sys\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "import albumentations as album\n",
    "# from one_cycle_lr_tf2 import OneCycleScheduler\n",
    "# from model_tf2 import create_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "# from my_generator_tf2 import MyGenerator\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import random\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger,Callback,LambdaCallback,TensorBoard)\n",
    "from tensorflow.keras import backend as K\n",
    "import tempfile\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, Multiply, Lambda,\n",
    "                          Concatenate, GlobalAveragePooling2D, Softmax)\n",
    "from tensorflow.keras import metrics\n",
    "# import pydicom\n",
    "import glob\n",
    "from scipy import ndimage\n",
    "from skimage import exposure\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "\n",
    "# from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "# import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_image_label(image, label):\n",
    "    # input image: (h,w,c) uint8\n",
    "    # input label: (h,w,c) uint8\n",
    "    seed_list = [random.randrange(2**32 - 1) for i in range(10)]\n",
    "\n",
    "    # augmentation pipeline for images\n",
    "    aug_images = iaa.Sequential([\n",
    "        iaa.Fliplr(p=0.5, random_state=seed_list[0]), \n",
    "        iaa.Flipud(p=0.5, random_state=seed_list[1]), \n",
    "        iaa.WithBrightnessChannels(iaa.Add((-50, 50)), random_state=seed_list[2]), \n",
    "        iaa.MultiplySaturation((0.5, 1.5), random_state=seed_list[3]), \n",
    "        # iaa.BlendAlpha((0.0, 0.1), iaa.contrast.AllChannelsHistogramEqualization(), random_state=seed_list[4]),\n",
    "        # iaa.Affine(scale=(0.9, 1.1), rotate=(-15, 15), random_state=seed_list[3], cval=255),\n",
    "        # iaa.PiecewiseAffine(scale=(0.01, 0.05), random_state=seed_list[4], cval=255), \n",
    "    ], random_state=seed_list[-1])\n",
    "\n",
    "    # augmentation pipeline for segmentation maps - with coarse dropout, but without color aug\n",
    "    aug_segmaps = iaa.Sequential([\n",
    "        iaa.Fliplr(p=0.5, random_state=seed_list[0]), \n",
    "        iaa.Flipud(p=0.5, random_state=seed_list[1]), \n",
    "        # iaa.Affine(scale=(0.9, 1.1), rotate=(-15, 15), random_state=seed_list[2]),\n",
    "        # iaa.PiecewiseAffine(scale=(0.01, 0.05), random_state=seed_list[4]), \n",
    "    ], random_state=seed_list[-1])\n",
    "    \n",
    "    image_aug = aug_images(image=image)  # First, augment image.\n",
    "    segmap_aug = aug_segmaps(image=label)  # Second, augment segmentation map.\n",
    "    return image_aug, segmap_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image = image / 255  # value[0.0-1.0]\n",
    "    return image.astype('float32')\n",
    "\n",
    "# function test\n",
    "# norm_image = normalize(image)\n",
    "# print(\"image min =\", norm_image.min())\n",
    "# print(\"image max =\", norm_image.max())\n",
    "def resize(image, scale=None, desired_size=(128,128)):\n",
    "    # Compute resize factors\n",
    "    if scale:\n",
    "        factor_0 = scale\n",
    "        factor_1 = scale\n",
    "    else:\n",
    "        factor_0 = 1 / (image.shape[0] / desired_size[1])\n",
    "        factor_1 = 1 / (image.shape[1] / desired_size[0])\n",
    "    # Resize\n",
    "    image = ndimage.zoom(image.astype('float32'), (factor_0, factor_1, 1), order=1, output='float32')\n",
    "    return image.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocessing(sample_id):\n",
    "    def py_preproc(sample_id):  # input tensor\n",
    "        # read\n",
    "        # image = get_image(sample_id)\n",
    "        # label = get_label(sample_id)\n",
    "        image = train_arr[sample_id]\n",
    "        label = label_arr[sample_id]\n",
    "        # augmentation\n",
    "        image, label = aug_image_label(image, label)\n",
    "        # # bilateralFilter\n",
    "        # image = cv2.bilateralFilter(image, d=d, sigmaColor=sigmaColor, sigmaSpace=sigmaSpace)\n",
    "        # normalize\n",
    "        image = normalize(image)\n",
    "        # resize\n",
    "        image = resize(image, desired_size=(128,128))\n",
    "        label = resize(label, desired_size=(128,128))   \n",
    "        # #RGB2GRAY\n",
    "        # image = np.mean(image, axis=2)\n",
    "        # image = np.expand_dims(image, axis=-1)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    image, label = tf.py_function(py_preproc, [sample_id], [tf.float16, tf.float16])\n",
    "    return image, label  # tensor output\n",
    "def valid_preprocessing(sample_id):\n",
    "    def py_preproc(sample_id):  # input tensor\n",
    "        # read\n",
    "        # image = get_image(sample_id)\n",
    "        # label = get_label(sample_id)\n",
    "        image = train_arr[sample_id]\n",
    "        label = label_arr[sample_id]\n",
    "        # # bilateralFilter\n",
    "        # image = cv2.bilateralFilter(image, d=d, sigmaColor=sigmaColor, sigmaSpace=sigmaSpace)\n",
    "        # normalize\n",
    "        image = normalize(image)\n",
    "        # resize\n",
    "        image = resize(image, desired_size=(128,128))\n",
    "        label = resize(label, desired_size=(128,128)) \n",
    "        # #RGB2GRAY\n",
    "        # image = np.mean(image, axis=2)\n",
    "        # image = np.expand_dims(image, axis =-1)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    image, label = tf.py_function(py_preproc, [sample_id], [tf.float16, tf.float16])\n",
    "    return image, label  # tensor output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
